{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to detect lanes and calculate center offset\n",
    "def detect_lanes_and_calculate_offset(frame):\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    # Define region of interest (ROI)\n",
    "    height, width = frame.shape[:2]\n",
    "    roi_vertices = np.array([[(0, height), (width / 2, height / 2), (width, height)]], dtype=np.int32)\n",
    "    roi_mask = np.zeros_like(edges)\n",
    "    cv2.fillPoly(roi_mask, roi_vertices, 255)\n",
    "    roi_edges = cv2.bitwise_and(edges, roi_mask)\n",
    "    \n",
    "    # Detect lines using Hough transform\n",
    "    lines = cv2.HoughLinesP(roi_edges, rho=1, theta=np.pi/180, threshold=50, minLineLength=50, maxLineGap=100)\n",
    "    \n",
    "    # Fit a polynomial to each lane line\n",
    "    left_lane_pts = []\n",
    "    right_lane_pts = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        slope = (y2 - y1) / (x2 - x1)\n",
    "        if slope < 0:  # Left lane\n",
    "            left_lane_pts.extend([(x1, y1), (x2, y2)])\n",
    "        elif slope > 0:  # Right lane\n",
    "            right_lane_pts.extend([(x1, y1), (x2, y2)])\n",
    "    \n",
    "    if left_lane_pts and right_lane_pts:\n",
    "        left_lane_pts = np.array(left_lane_pts)\n",
    "        right_lane_pts = np.array(right_lane_pts)\n",
    "        \n",
    "        left_lane_params = np.polyfit(left_lane_pts[:, 0], left_lane_pts[:, 1], 1)\n",
    "        right_lane_params = np.polyfit(right_lane_pts[:, 0], right_lane_pts[:, 1], 1)\n",
    "        \n",
    "        left_lane_bottom = np.polyval(left_lane_params, height)\n",
    "        right_lane_bottom = np.polyval(right_lane_params, height)\n",
    "        \n",
    "        center_offset = (width / 2) - ((left_lane_bottom + right_lane_bottom) / 2)\n",
    "    else:\n",
    "        center_offset = 0\n",
    "    \n",
    "    return center_offset\n",
    "\n",
    "# Function to map center offset to steering angle\n",
    "def map_offset_to_steering_angle(center_offset):\n",
    "    # Mapping logic: You may need to adjust this based on your specific setup\n",
    "    steering_angle = np.arctan(center_offset / 320) * (180 / np.pi)  # Assuming frame width is 640\n",
    "    \n",
    "    return steering_angle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "cap = cv2.VideoCapture(0) \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame\")\n",
    "        break\n",
    "    \n",
    "    # Detect lanes and calculate center offset\n",
    "    center_offset = detect_lanes_and_calculate_offset(frame)\n",
    "    \n",
    "    # Map center offset to steering angle\n",
    "    steering_angle = map_offset_to_steering_angle(center_offset)\n",
    "    \n",
    "    # Print steering angle (for demonstration)\n",
    "    print(\"Steering angle:\", steering_angle)\n",
    "    \n",
    "    # Display frame with lane detection (for visualization)\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    # Check for key press to quit\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
